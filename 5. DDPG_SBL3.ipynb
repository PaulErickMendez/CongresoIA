{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["tF42HvI7-gs5","nWAuOOLh-oQf"],"gpuType":"T4","authorship_tag":"ABX9TyO8P8bOlujMeKhgqp1GXY+d"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Panda-Gym con Stable-baseline3 ü§ñ\n","\n","\n","El objetivo es usar los algoritmos ya implementados para el entrenamiento de entornos, en esta ocasi√≥n se usar√° el entorno de [Panda-Gym](https://github.com/qgallouedec/panda-gym). Entrenar√°s un **brazo rob√≥tico** (el robot Franka Emika Panda) para realizar un tarea.\n","\n","- `Reach`: el robot debe colocar su efector final en una posici√≥n objetivo.\n","\n","Despu√©s de eso, podr√°s **entrenar en otras tareas rob√≥ticas**."],"metadata":{"id":"-PTReiOw-RAN"}},{"cell_type":"markdown","source":["### üéÆ Entorno:\n","\n","- [Panda-Gym](https://github.com/qgallouedec/panda-gym)\n","\n","###üìö Libreria RL:\n","\n","- [Stable-Baselines3](https://stable-baselines3.readthedocs.io/)"],"metadata":{"id":"QInFitfWno1Q"}},{"cell_type":"markdown","source":["## Objectivos üèÜ\n","\n","* Utilizar un entorno rob√≥tico como panda-gym\n","* Emplear una librer√≠a de algoritmos de aprendizaje por refuerzo\n","* Tips para la implementaci√≥n de los algoritmos\n","\n","\n"],"metadata":{"id":"MoubJX20oKaQ"}},{"cell_type":"markdown","source":["# Configuraci√≥n ü§ñ"],"metadata":{"id":"iajHvVDWoo01"}},{"cell_type":"markdown","source":["## Crear una pantalla virtual üîΩ\n","\n","Durante la ejecuci√≥n, necesitaremos generar un video de repetici√≥n. Para hacerlo, en colab, **necesitamos tener una pantalla virtual para poder renderizar el entorno** (y as√≠ grabar los fotogramas).\n","\n","Por lo tanto, la siguiente celda instalar√° las librer√≠as, crear√° y ejecutar√° una pantalla virtual üñ•."],"metadata":{"id":"bTpYcVZVMzUI"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"jV6wjQ7Be7p5","executionInfo":{"status":"ok","timestamp":1744304393646,"user_tz":360,"elapsed":12379,"user":{"displayName":"Paul Erick M√©ndez Monroy","userId":"05949060174698851934"}}},"outputs":[],"source":["%%capture\n","!apt install python-opengl\n","!apt install ffmpeg\n","!apt install xvfb\n","!pip3 install pyvirtualdisplay"]},{"cell_type":"code","source":["# monitor virtual\n","from pyvirtualdisplay import Display\n","\n","virtual_display = Display(visible=0, size=(1400, 900))\n","virtual_display.start()"],"metadata":{"id":"ww5PQH1gNLI4","executionInfo":{"status":"ok","timestamp":1744304394546,"user_tz":360,"elapsed":895,"user":{"displayName":"Paul Erick M√©ndez Monroy","userId":"05949060174698851934"}},"outputId":"ad2401c0-de8e-4e2a-892a-948bf135d6c1","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pyvirtualdisplay.display.Display at 0x7f2ebd41d910>"]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["### Instalar dependencias üîΩ\n","\n","El primer paso es instalar las dependencias, instalaremos varias:\n","- `gymnasium`\n","- `panda-gym`: Contiene los entornos del brazo rob√≥tico.\n","- `stable-baselines3`: La biblioteca de aprendizaje profundo de refuerzo SB3.\n","\n","‚è≤ La instalaci√≥n puede **tardar 10 minutos**."],"metadata":{"id":"e1obkbdJ_KnG"}},{"cell_type":"code","source":["!pip install stable-baselines3[extra]\n","!pip install gymnasium\n","!pip install panda_gym"],"metadata":{"id":"TgZUkjKYSgvn","collapsed":true,"executionInfo":{"status":"ok","timestamp":1744304508730,"user_tz":360,"elapsed":114182,"user":{"displayName":"Paul Erick M√©ndez Monroy","userId":"05949060174698851934"}},"outputId":"6709faec-53f4-4806-e8ba-b29f901bf0f9","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting stable-baselines3[extra]\n","  Downloading stable_baselines3-2.6.0-py3-none-any.whl.metadata (4.8 kB)\n","Requirement already satisfied: gymnasium<1.2.0,>=0.29.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (1.1.1)\n","Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.0.2)\n","Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.6.0+cu124)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (3.1.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.2.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (3.10.0)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (4.11.0.86)\n","Requirement already satisfied: pygame in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.6.1)\n","Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (2.18.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (5.9.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (4.67.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (13.9.4)\n","Requirement already satisfied: ale-py>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (0.10.2)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from stable-baselines3[extra]) (11.1.0)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.2.0,>=0.29.1->stable-baselines3[extra]) (4.13.1)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.2.0,>=0.29.1->stable-baselines3[extra]) (0.0.4)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.71.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.7)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (24.2)\n","Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (5.29.4)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (75.2.0)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.17.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.1.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.18.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2025.3.2)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0,>=2.3->stable-baselines3[extra])\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0,>=2.3->stable-baselines3[extra])\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0,>=2.3->stable-baselines3[extra])\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0,>=2.3->stable-baselines3[extra])\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0,>=2.3->stable-baselines3[extra])\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0,>=2.3->stable-baselines3[extra])\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0,>=2.3->stable-baselines3[extra])\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3[extra]) (1.3.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (4.57.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.8)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3[extra]) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable-baselines3[extra]) (2025.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->stable-baselines3[extra]) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.2)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading stable_baselines3-2.6.0-py3-none-any.whl (184 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m184.5/184.5 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stable-baselines3\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 stable-baselines3-2.6.0\n","Requirement already satisfied: gymnasium in /usr/local/lib/python3.11/dist-packages (1.1.1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (2.0.2)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (3.1.1)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (4.13.1)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (0.0.4)\n","Collecting panda_gym\n","  Downloading panda_gym-3.0.7-py3-none-any.whl.metadata (4.3 kB)\n","Requirement already satisfied: gymnasium>=0.26 in /usr/local/lib/python3.11/dist-packages (from panda_gym) (1.1.1)\n","Collecting pybullet (from panda_gym)\n","  Downloading pybullet-3.2.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from panda_gym) (2.0.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from panda_gym) (1.14.1)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=0.26->panda_gym) (3.1.1)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=0.26->panda_gym) (4.13.1)\n","Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=0.26->panda_gym) (0.0.4)\n","Downloading panda_gym-3.0.7-py3-none-any.whl (23 kB)\n","Downloading pybullet-3.2.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (103.2 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m103.2/103.2 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pybullet, panda_gym\n","Successfully installed panda_gym-3.0.7 pybullet-3.2.7\n"]}]},{"cell_type":"code","source":["import os\n","\n","import gymnasium as gym\n","import panda_gym\n","\n","from stable_baselines3 import DDPG\n","from stable_baselines3.common.evaluation import evaluate_policy\n","from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n","from stable_baselines3.common.env_util import make_vec_env\n"],"metadata":{"id":"HpiB8VdnQ7Bk","executionInfo":{"status":"ok","timestamp":1744304527570,"user_tz":360,"elapsed":18833,"user":{"displayName":"Paul Erick M√©ndez Monroy","userId":"05949060174698851934"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## PandaReachDense-v3 ü¶æ\n","\n","El agente que vamos a entrenar es un brazo rob√≥tico que necesita realizar controles (mover el brazo y utilizar el efector final).\n","\n","En rob√≥tica, el *efector final* es el dispositivo en el extremo de un brazo rob√≥tico dise√±ado para interactuar con el entorno.\n","\n","En `PandaReach`, el robot debe colocar su efector final en una posici√≥n objetivo (bola verde). [Otros entornos de panda-gym](https://panda-gym.readthedocs.io/en/latest/usage/environments.html)\n","\n","Vamos a usar la versi√≥n densa de este entorno. Esto significa que tendremos una *funci√≥n de recompensa densa* que **proporcionar√° una recompensa en cada paso de tiempo** (cuanto m√°s cerca est√© el agente de completar la tarea, mayor ser√° la recompensa). A diferencia de una *funci√≥n de recompensa escasa*, donde el entorno **solo devuelve una recompensa si y solo si la tarea se completa**.\n","\n","Tambi√©n vamos a usar el *control de desplazamiento del efector final*, lo que significa que la **acci√≥n corresponde al desplazamiento del efector final**. No controlamos el movimiento individual de cada articulaci√≥n (control por articulaci√≥n).\n","\n","<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcR90do7v-58OGvPW4Gyd2ZNSjw4BJIzu8Qi-w&s\" />\n","\n","De esta manera **el entrenamiento ser√° m√°s f√°cil**."],"metadata":{"id":"lfBwIS_oAVXI"}},{"cell_type":"code","source":["env_id = \"PandaReachDense-v3\"\n","\n","# Create the env\n","env = gym.make(env_id)\n","\n","# Get the state space and action space\n","s_size = env.observation_space.shape\n","a_size = env.action_space"],"metadata":{"id":"zXzAu3HYF1WD","executionInfo":{"status":"ok","timestamp":1744304528257,"user_tz":360,"elapsed":684,"user":{"displayName":"Paul Erick M√©ndez Monroy","userId":"05949060174698851934"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["El espacio de observaci√≥n **es un diccionario con 3 elementos diferentes**:\n","- `achieved_goal`: (x,y,z) la posici√≥n actual del efector final.\n","- `desired_goal`: (x,y,z) la posici√≥n objetivo para el efector final.\n","- `observation`: posici√≥n (x,y,z) y velocidad del efector final (vx, vy, vz).\n","\n","Dado que es un diccionario como observaci√≥n, **necesitaremos usar una pol√≠tica MultiInputPolicy en lugar de MlpPolicy**.\n","\n","El espacio de acci√≥n es un vector con 3 valores:\n","- Control del movimiento en x, y, z."],"metadata":{"id":"g_JClfElGFnF"}},{"cell_type":"code","source":["print(\"_____OBSERVATION SPACE_____ \\n\")\n","print(\"The State Space is: \", s_size)\n","print(\"Sample observation\", env.observation_space.sample()) # Get a random observation\n","print(\"\\n _____ACTION SPACE_____ \\n\")\n","print(\"The Action Space is: \", a_size)\n","print(\"Action Space Sample\", env.action_space.sample()) # Take a random action"],"metadata":{"id":"E-U9dexcF-FB","executionInfo":{"status":"ok","timestamp":1744304528273,"user_tz":360,"elapsed":13,"user":{"displayName":"Paul Erick M√©ndez Monroy","userId":"05949060174698851934"}},"outputId":"7b1283eb-f2e9-4f92-bacb-158f09493b6d","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["_____OBSERVATION SPACE_____ \n","\n","The State Space is:  None\n","Sample observation {'achieved_goal': array([-0.75458986,  1.0464022 ,  3.1721694 ], dtype=float32), 'desired_goal': array([ 9.026851,  1.2366  , -4.128559], dtype=float32), 'observation': array([ 8.380305  ,  5.9903316 , -8.513405  , -9.195543  , -4.827909  ,\n","        0.29232147], dtype=float32)}\n","\n"," _____ACTION SPACE_____ \n","\n","The Action Space is:  Box(-1.0, 1.0, (3,), float32)\n","Action Space Sample [0.41930375 0.051084   0.36307752]\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import imageio\n","\n","# Configurar la pantalla virtual\n","display = Display(visible=0, size=(1400, 900))\n","display.start()\n","\n","# Crear el entorno\n","env = gym.make(\"PandaReachDense-v3\", render_mode=\"rgb_array\")\n","obs = env.reset()\n","\n","# Lista para almacenar los fotogramas\n","frames = []\n","\n","# Ejecutar pasos y guardar fotogramas\n","for step in range(50):  # N√∫mero de pasos\n","    action = env.action_space.sample()  # Tomar acciones aleatorias\n","    obs, reward, terminated, truncated, info = env.step(action)  # Hacer un paso en el entorno\n","\n","    # Renderizar y guardar el fotograma\n","    img = env.render()\n","    frames.append(img)\n","\n","    if terminated or truncated:  # Reiniciar el entorno si se alcanza el objetivo\n","        obs = env.reset()\n","\n","# Cerrar el entorno\n","env.close()\n","\n","# Guardar los fotogramas como GIF\n","gif_path = \"panda_gym_render.gif\"\n","imageio.mimsave(gif_path, frames, fps=10)\n","print(f\"GIF guardado con √©xito: {gif_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W6YChaZdktza","executionInfo":{"status":"ok","timestamp":1744304550297,"user_tz":360,"elapsed":22017,"user":{"displayName":"Paul Erick M√©ndez Monroy","userId":"05949060174698851934"}},"outputId":"1d9d55d6-09f6-4893-8ca2-65911f648aff"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/imageio/plugins/pillow.py:409: DeprecationWarning: The keyword `fps` is no longer supported. Use `duration`(in ms) instead, e.g. `fps=50` == `duration=20` (1000 * 1/50).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["GIF guardado con √©xito: panda_gym_render.gif\n"]}]},{"cell_type":"markdown","source":["### Normalizar las observaciones y recompensas"],"metadata":{"id":"S5sXcg469ysB"}},{"cell_type":"markdown","source":["Una buena pr√°ctica en el aprendizaje por refuerzo es [normalizar las caracter√≠sticas de entrada](https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html) a√±adiendo `norm_obs = True`.\n","\n","Para ello, existe un wrapper que calcular√° un promedio m√≥vil y la desviaci√≥n est√°ndar de las caracter√≠sticas de entrada.\n","\n","Tambi√©n normalizamos las recompensas con este mismo wrapper a√±adiendo `norm_reward = True`.\n","\n","[Deber√≠as consultar la documentaci√≥n para completar esta celda](https://stable-baselines3.readthedocs.io/en/master/guide/vec_envs.html#vecnormalize)."],"metadata":{"id":"1ZyX6qf3Zva9"}},{"cell_type":"code","source":["# make_vec_env es parte de stable-baseline3\n","env = make_vec_env(env_id, n_envs=4)\n","\n","# Agrega aqui la instrucci√≥n para normalizar las observaciones y la recompensa\n","env = # TODO: Add the wrapper"],"metadata":{"id":"1RsDtHHAQ9Ie"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Solution"],"metadata":{"id":"tF42HvI7-gs5"}},{"cell_type":"code","source":["env = make_vec_env(env_id, n_envs=4)\n","\n","env = VecNormalize(env, norm_obs=True, norm_reward=True, clip_obs=10.)"],"metadata":{"id":"2O67mqgC-hol","executionInfo":{"status":"ok","timestamp":1744304875972,"user_tz":360,"elapsed":617,"user":{"displayName":"Paul Erick M√©ndez Monroy","userId":"05949060174698851934"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["### Create un agente DDPG con SBL3 ü§ñ\n","\n","Para m√°s informaci√≥n sobre la implementaci√≥n de DDPG con StableBaselines3, consulta: https://stable-baselines3.readthedocs.io/en/master/modules/ddpg.html#notes\n","\n","Para encontrar los mejores par√°metros, revis√© los [agentes entrenados oficialmente por el equipo de Stable-Baselines3](https://huggingface.co/sb3)."],"metadata":{"id":"4JmEVU6z1ZA-"}},{"cell_type":"code","source":["agent = # Crea un agente DDPG, con politica MultiInputPolicy"],"metadata":{"id":"vR3T4qFt164I"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Solution"],"metadata":{"id":"nWAuOOLh-oQf"}},{"cell_type":"code","source":["agent = DDPG(policy = \"MultiInputPolicy\",\n","            env = env,\n","            verbose=1)"],"metadata":{"id":"FKFLY54T-pU1","executionInfo":{"status":"ok","timestamp":1744304886517,"user_tz":360,"elapsed":7091,"user":{"displayName":"Paul Erick M√©ndez Monroy","userId":"05949060174698851934"}},"outputId":"8a6eb938-6fbd-4b15-ac1b-1e2da14ce2ee","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Using cpu device\n"]}]},{"cell_type":"markdown","source":["### Entrenamiento del agente üèÉ\n","- Vamos entrenar el agente por 1000,000 de pasos, si puedes usa colab con GPU. Tardar√° alrededor de 25~40min"],"metadata":{"id":"opyK3mpJ1-m9"}},{"cell_type":"code","source":["agent.learn(1000_000)"],"metadata":{"id":"4TuGHZD7RF1G","executionInfo":{"status":"ok","timestamp":1744304900228,"user_tz":360,"elapsed":9153,"user":{"displayName":"Paul Erick M√©ndez Monroy","userId":"05949060174698851934"}},"outputId":"ec3913fe-2c9c-485e-b258-857b2c92f5de","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 43.2     |\n","|    ep_rew_mean     | -11.9    |\n","|    success_rate    | 0.25     |\n","| time/              |          |\n","|    episodes        | 4        |\n","|    fps             | 126      |\n","|    time_elapsed    | 1        |\n","|    total_timesteps | 200      |\n","| train/             |          |\n","|    actor_loss      | 0.18     |\n","|    critic_loss     | 0.00142  |\n","|    learning_rate   | 0.001    |\n","|    n_updates       | 24       |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 46.6     |\n","|    ep_rew_mean     | -24.2    |\n","|    success_rate    | 0.125    |\n","| time/              |          |\n","|    episodes        | 8        |\n","|    fps             | 102      |\n","|    time_elapsed    | 3        |\n","|    total_timesteps | 400      |\n","| train/             |          |\n","|    actor_loss      | 0.132    |\n","|    critic_loss     | 0.000251 |\n","|    learning_rate   | 0.001    |\n","|    n_updates       | 74       |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 47.8     |\n","|    ep_rew_mean     | -24      |\n","|    success_rate    | 0.0833   |\n","| time/              |          |\n","|    episodes        | 12       |\n","|    fps             | 105      |\n","|    time_elapsed    | 5        |\n","|    total_timesteps | 600      |\n","| train/             |          |\n","|    actor_loss      | 0.179    |\n","|    critic_loss     | 0.00012  |\n","|    learning_rate   | 0.001    |\n","|    n_updates       | 124      |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 48.3     |\n","|    ep_rew_mean     | -27.3    |\n","|    success_rate    | 0.0625   |\n","| time/              |          |\n","|    episodes        | 16       |\n","|    fps             | 107      |\n","|    time_elapsed    | 7        |\n","|    total_timesteps | 800      |\n","| train/             |          |\n","|    actor_loss      | 0.196    |\n","|    critic_loss     | 5.34e-05 |\n","|    learning_rate   | 0.001    |\n","|    n_updates       | 174      |\n","---------------------------------\n","---------------------------------\n","| rollout/           |          |\n","|    ep_len_mean     | 48.6     |\n","|    ep_rew_mean     | -26.1    |\n","|    success_rate    | 0.05     |\n","| time/              |          |\n","|    episodes        | 20       |\n","|    fps             | 109      |\n","|    time_elapsed    | 9        |\n","|    total_timesteps | 1000     |\n","| train/             |          |\n","|    actor_loss      | 0.206    |\n","|    critic_loss     | 2.74e-05 |\n","|    learning_rate   | 0.001    |\n","|    n_updates       | 224      |\n","---------------------------------\n"]},{"output_type":"execute_result","data":{"text/plain":["<stable_baselines3.ddpg.ddpg.DDPG at 0x7f2d52cacc50>"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# Salva el modelo y los par√°metros de normalizaci√≥n en el drive, para usarlos despu√©s.\n","#agent.save(\"/content/drive/mydrive/colab notebooks/DDPG_agent\")\n","#env.save(\"/content/drive/mydrive/colab notebooks/DDPG_vec_normalize.pkl\")\n","\n","# Salva el modelo y los par√°metros de normalizaci√≥n en el colab actual, estos se borrar√°n al terminar sesi√≥n.\n","agent.save(\"ddpg-PandaReachDense-v3\")\n","env.save(\"vec_normalize.pkl\")"],"metadata":{"id":"MfYtjj19cKFr","executionInfo":{"status":"ok","timestamp":1744304999192,"user_tz":360,"elapsed":30,"user":{"displayName":"Paul Erick M√©ndez Monroy","userId":"05949060174698851934"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["### Evaluar el agente üìà\n","- Ya con el agente entrenado necesitamos **revisar sus desempe√±o**.\n","- Stable-Baselines3 tiene un m√©todo para revisar el agente: `evaluate_policy`"],"metadata":{"id":"01M9GCd32Ig-"}},{"cell_type":"code","source":["from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n","\n","# carga los par√°metros de normalizaci√≥n\n","eval_env = DummyVecEnv([lambda: gym.make(\"PandaReachDense-v3\")])\n","eval_env = VecNormalize.load(\"vec_normalize.pkl\", eval_env)\n","\n","# Se necesita el render rgb_array para colab\n","eval_env.render_mode = \"rgb_array\"\n","\n","#  Deshabilita el entrenamiento\n","eval_env.training = False\n","# No se requiere normalizaci√≥n de la recompensa ya que no se esta entrenando\n","eval_env.norm_reward = False\n","\n","# Carga el agente\n","agent = DDPG.load(\"ddpg-PandaReachDense-v3\")\n","\n","mean_reward, std_reward = evaluate_policy(agent, eval_env)\n","\n","print(f\"Mean reward = {mean_reward:.2f} +/- {std_reward:.2f}\")"],"metadata":{"id":"liirTVoDkHq3","executionInfo":{"status":"ok","timestamp":1744305019006,"user_tz":360,"elapsed":2151,"user":{"displayName":"Paul Erick M√©ndez Monroy","userId":"05949060174698851934"}},"outputId":"31e12be0-e7c4-4204-c27d-b3af54c7b739","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Mean reward = -26.90 +/- 8.00\n"]}]},{"cell_type":"code","source":["# Crear el entorno\n","#env = gym.make(\"PandaReachDense-v3\", render_mode=\"rgb_array\")\n","obs = eval_env.reset()\n","\n","# Lista para almacenar los fotogramas\n","frames = []\n","\n","# Ejecutar pasos y guardar fotogramas\n","for step in range(50):  # N√∫mero de pasos\n","    action, _ = agent.predict(obs, deterministic=True)  # Tomar acciones del agente\n","    obs, reward, done, info = eval_env.step(action)  # Hacer un paso en el entorno\n","\n","    # Renderizar y guardar el fotograma\n","    img = eval_env.render()\n","    frames.append(img)\n","\n","    if done:  # Reiniciar el entorno si se alcanza el objetivo\n","        obs = eval_env.reset()\n","\n","# Cerrar el entorno\n","eval_env.close()\n","\n","# Guardar los fotogramas como GIF\n","gif_path = \"panda_gym_render_trained.gif\"\n","imageio.mimsave(gif_path, frames, fps=10)\n","print(f\"GIF guardado con √©xito: {gif_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eESPjN2hoPKw","executionInfo":{"status":"ok","timestamp":1744305504343,"user_tz":360,"elapsed":17895,"user":{"displayName":"Paul Erick M√©ndez Monroy","userId":"05949060174698851934"}},"outputId":"6710c174-8bd1-4b3d-9374-0b8ad02f3eb8"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/imageio/plugins/pillow.py:409: DeprecationWarning: The keyword `fps` is no longer supported. Use `duration`(in ms) instead, e.g. `fps=50` == `duration=20` (1000 * 1/50).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["GIF guardado con √©xito: panda_gym_render_trained.gif\n"]}]}]}